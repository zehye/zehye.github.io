---
layout: post
title: 머신러닝 - 차원의 저주와 주성분 분석(PCA)
category: Machine Learning
tags: [Machine Learning]
comments: true
---

> 개인공부 후 자료를 남기기 위한 목적임으로 내용 상에 오류가 있을 수 있습니다.    

<hr>

## 차원의 저주(Curse of Dimensionality)란?

데이터의 차원(dimension), 즉 특성(feature)의 수가 너무 많아져서 발생하는 총체적인 문제

데이터의 차원(변수의 수)가 증가함에 따라
1. 모델의 성능이 저하되고
2. 계산 비용이 증가하는 현상이 발생함!

고차원 데이터는 표본이 실제 공간에 비해 매우 적어져서, 모델이 유의미한 패턴을 학습하기 어려워지고 이는 곧 예측 정확도를 떨어뜨리는 중요한 원인이 될 수 있다.

이를 해결하는 방법으로 `차원축소(Dimensionality Reduction)`이 있다.

이는 차원이 늘어나서 발생한 문제를 차원을 줄임으로서 해결하는 것을 의미한다.

1. 특징 선택(Feature Selection): 원래 특징 중에서 가장 중요하거나 유의미한 특징들을 선택하여 차원 줄이기
2. 특징 추출(Feature Extraction): 기존 특징들을 조합하여 새로운, 더 적은 수의 특징을 만들어내기 (PCA(주성분 분석)가 하나의 예시)


## 주성분분석(PCA-Pricipal Component Analysis)

데이터의 차원(특성, 변수의 수)를 줄이는 차원 축소 기법

이는 비지도학습에서 대표적으로 차원 축소 용도로 쓰이는 기법으로 머신러닝, 통계분석, 노이즈 제거 등 다양하게 사용된다. 

1. 여러변수(특성)를 몇개의 주성분으로 요약해서
2. 데이터 정보 손실을 최소화하면서
3. 변수 수를 줄이려는 목적이 큼


### Q. PCA 없이 데이터를 시각화 할수도 있지 않나?

특정 칼럼을 뽑아서 하는것과 같이 이러한 방법으로도 가능은 하지만, 변수가 여러개인데 바로 시각화를 처리하려고 하면 데이터가 왜곡될 가능성이 있다. 따라서 특성(변수)이 2개 이상이라면, 주성분분석과 같은 차원축소를 통해 시각화를 하는 것이 좋다!